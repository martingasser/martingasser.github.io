[{"_path":"/works/bachmann-kuppel-2","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Ingeborg Bachmann-Kuppel Karlsplatz","description":"Sound","type":"art project","url":"https://bachmann-kuppel.at/","tags":["sound installation","voice recording","SuperCollider","live performance","composition"],"year":2023,"img":"/works/media/bachmann-kuppel-2.jpg","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the second public installation at Karlsplatz Vienna, April 21-May 17 2023, the soundtrack was redesigned. It interweaves texts by Ingeborg Bachmann and the Viennese author "},{"type":"element","tag":"a","props":{"href":"http://www.limbusverlag.at/index.php/meschik-lukas","rel":["nofollow"]},"children":[{"type":"text","value":"Lukas Meschik"}]},{"type":"text","value":"."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/6TDICCnsfzg","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the soundtrack, a text collage is spoken by 3 different speakers, and the recordings are spectrally analyzed using an algorithm called Constant-Q transform (CQT). The CQT is carried out with a bin width of one semitone and the results of this spectral analysis can be directly mapped to MIDI control signals for a synthesizer. The duration of the text is approximately 25 minutes, and while the chronological order of the text fragments spoken by different speakers is fixed, the selection of the actual speaker is controlled by a random process, which makes each completion of the text a unique experience. This approach was partially inspired by Peter Ablinger's "},{"type":"element","tag":"a","props":{"href":"https://ablinger.mur.at/speaking_piano.html","rel":["nofollow"]},"children":[{"type":"text","value":"Speaking Piano"}]},{"type":"text","value":" and spectral composition in general, and it points out the musical qualities of language and speech."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Team:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"http://www.guerino.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Armin Guerino"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.gerhardfresacher.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Gerhard Fresacher"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Anna Valentina Ennemoser"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:bachmann-kuppel-2.md","_source":"content","_file":"works/bachmann-kuppel-2.md","_extension":"md"},{"_path":"/works/brick-by-brick","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Brick by Brick","description":"Sound/Performance","type":"art project","tags":["sound installation","performance","composition"],"year":2023,"img":"/works/media/brick-by-brick.png","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"What are the limits of our endurance? This existential question arises within a social and a political context. The installation 'Brick by Brick' delves into the intricate web of seemingly insurmountable constraints and societal expectations to which we find ourselves subjected in our everyday existence."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/cd3l2zjyF8g?si=7rrtAw4W5pej3LqZ","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Symbolically, a stack of bricks serves as a metaphor for these burdens, inviting the audience to intermittently engage with a sledgehammer, fostering a moment of profound release that coincides with an encompassing infusion of illuminative visual stimuli and resonant auditory experiences. Thereby, each hit of the hammer triggers the next section of a six-part musical composition."}]},{"type":"element","tag":"iframe","props":{"width":"100%","height":166,"scrolling":"no","frameBorder":"no","allow":"autoplay","src":"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1634021337&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"},"children":[]},{"type":"element","tag":"div","props":{"style":"font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"},"children":[{"type":"element","tag":"a","props":{"href":"https://soundcloud.com/martin-alley","title":"Martin Alley","target":"_blank","style":"color: #cccccc; text-decoration: none;"},"children":[{"type":"text","value":"Martin Alley"}]},{"type":"text","value":" · "},{"type":"element","tag":"a","props":{"href":"https://soundcloud.com/martin-alley/brick-by-brick","title":"Brick By Brick","target":"_blank","style":"color: #cccccc; text-decoration: none;"},"children":[{"type":"text","value":"Brick By Brick"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the technical realization, a piezo pickup glued to a massive wooden plate, with the bricks stacked on top of it is used to detect the hammer hits. The piezo is connected to a ESP32 microcontroller with a Bluetooth LE connection to a laptop running Max/MSP and Ableton Live. Max/MSP takes care of receiving the trigger signals via BLE. The parts of the composition are laid out in Ableton Live as scenes that can be triggered via MIDI by the Max/MSP patch. The Max/MSP patch also controls DMX lighting. A 2x 500W audio system plus subwoofer was used to render the soundscape."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It was exhibited from 28.-30. September 2023 at "},{"type":"element","tag":"a","props":{"href":"https://www.dark-city.at/other-island/","rel":["nofollow"]},"children":[{"type":"text","value":"Other Island"}]},{"type":"text","value":"."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:brick-by-brick.md","_source":"content","_file":"works/brick-by-brick.md","_extension":"md"},{"_path":"/works/spin-wave-voices","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Spin-Wave Voices","description":"Interactive visualization and sonification of simulation data","type":"art project","img":"/works/media/cyces.png","year":2022,"tags":["visualization","sonification","simulation","physics","art"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We are in a search of alternative ways of living, more efficient, less energy consuming ways. But some of the modern technologies are so small and fast that they are already out of the range of our perception. The future will bring something even more sophisticated. Did you ever try to imagine how all those gigabytes and billions of gigabytes of information are processed and transferred around the world so quickly? Researchers are already working on alternative, faster, more efficient way of doing that as well. With this exhibit we did our best to bring you closer to the possible future of computational technologies."}]},{"type":"element","tag":"p","props":{},"children":[]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/QGWoRnfgXfI","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[]},{"type":"element","tag":"p","props":{},"children":[]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/FnNImplHFG4","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[]},{"type":"element","tag":"h3","props":{"id":"team"},"children":[{"type":"text","value":"Team:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Project lead"}]},{"type":"text","value":": Santa Pile (Institute of Semiconductor and Solid State Physics JKU Linz)"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Artistic lead"}]},{"type":"text","value":": Martin Gasser (University of Applied Arts Vienna)"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Visualisation"}]},{"type":"text","value":": Santa Pile, Christina Humer (Institute of Computer Graphics JKU Linz)"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Sonification"}]},{"type":"text","value":": Martin Gasser, Silvan David Peter (Institute of Computational Perception JKU Linz)"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Micromagnetic simulations"}]},{"type":"text","value":": Santa Pile"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Video production"}]},{"type":"text","value":": Santa Pile, Oleg Lesota (Institute of Computational Perception JKU)"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Consult/help at the exhibition"}]},{"type":"text","value":": Andreas Ney (Institute of Semiconductor and Solid State Physics JKU Linz), Verena Ney (Institute of Semiconductor and Solid State Physics JKU Linz), Marc Streit (Institute of Computer Graphics JKU Linz)"}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"team","depth":3,"text":"Team:"}]}},"_type":"markdown","_id":"content:works:spin-wave-voices.md","_source":"content","_file":"works/spin-wave-voices.md","_extension":"md"},{"_path":"/works/bachmann-kuppel","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Ingeborg Bachmann-Kuppel","description":"Sound","type":"art project","url":"https://bachmann-kuppel.at/","tags":["sound installation","voice recording","SuperCollider","live performance","composition"],"year":2021,"img":"/works/media/bachmann-kuppel.jpg","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For Armin Guerino's and Gerhard Fresacher's dome installation, I developed a generative sound work that brings texts by the Austrian authors Ingeborg Bachmann and Gert Jonke into context with each other. The sound installation is inspired by Bachmann's frequent use of the topic transientness and Jonke's concept of Language as Music."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://player.vimeo.com/video/608485662?h=7ec8e342be&badge=0&autopause=0&player_id=0&app_id=58479","frameBorder":"0","allow":"autoplay; fullscreen; picture-in-picture","allowFullScreen":true,"style":"position:absolute;top:0;left:0;width:100%;height:100%;","title":"Ingeborg Bachmann-Kuppel"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The permanent sound installation oscillates between a grain cloud generated from recordings of Bachmann texts and a random selection of concrete Bachmann and Jonke texts, creating a virtual conversation between the two authors. Each text is accompanied by a piano part that is generated by analyzing the speech signal and triggering piano tones by the fundamental frequencies of the human voice, thereby removing the actual meaning of the words and leaving only the musical aspect of the spoken text."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The software was implemented in SuperCollider and it runs on a Raspberry Pi computer."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the opening ceremony of the dome installation, I composed music inspired by the texts, which was performed live by the pianist "},{"type":"element","tag":"a","props":{"href":"https://www.anatijssen.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Ana Tijssen"}]},{"type":"text","value":" and myself."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"See this "},{"type":"element","tag":"a","props":{"href":"https://kaernten.orf.at/stories/3121955/?fbclid=IwAR1ftTySgrCQUJ_d4ib7a1xWQSYSDk1nrFuLx05ddt0QlSgKn0wpzD_Kubg","rel":["nofollow"]},"children":[{"type":"text","value":"ORF"}]},{"type":"text","value":" report."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"http://www.guerino.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Armin Guerino"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.gerhardfresacher.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Gerhard Fresacher"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://de.wikipedia.org/wiki/Anne_Bennent","rel":["nofollow"]},"children":[{"type":"text","value":"Anne Bennent"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.imdb.com/name/nm0919406/","rel":["nofollow"]},"children":[{"type":"text","value":"Heinz Weixelbraun"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.anatijssen.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Ana Tijssen"}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:bachmann-kuppel.md","_source":"content","_file":"works/bachmann-kuppel.md","_extension":"md"},{"_path":"/works/co-corporeality-2","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Co-Corporeality@Angewandte Festival 2021","description":"Artistic Research Project","type":"research project","tags":["machine learning","computer vision","facial expression recognition"],"img":"/works/media/eyetracking.png","year":2021,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the "},{"type":"element","tag":"a","props":{"href":"https://cocorporeality.net/","rel":["nofollow"]},"children":[{"type":"text","value":"Co-Corporeality"}]},{"type":"text","value":" artistic research project, we have developed a mobile eye tracking solution. It consists of a "},{"type":"element","tag":"a","props":{"href":"https://pupil-labs.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Pupil Labs"}]},{"type":"text","value":" eye camera, an "},{"type":"element","tag":"a","props":{"href":"https://www.intelrealsense.com/tracking-camera-t265/","rel":["nofollow"]},"children":[{"type":"text","value":"Intel Realsense T265"}]},{"type":"text","value":" tracking camera, and an "},{"type":"element","tag":"a","props":{"href":"https://www.intelrealsense.com/depth-camera-d435/","rel":["nofollow"]},"children":[{"type":"text","value":"Intel Realsense D435"}]},{"type":"text","value":" world camera, mounted on a bike helmet. A "},{"type":"element","tag":"a","props":{"href":"https://www.raspberrypi.org/products/raspberry-pi-4-model-b/","rel":["nofollow"]},"children":[{"type":"text","value":"Raspberry Pi 4"}]},{"type":"text","value":" is used to compress and transmit the image data over Ethernet to another computer where a combination of the Pupil Labs software and custom software components is used to determine the exact position and gaze direction of a viewer in space. This information can be subsequently used to detect which objects a person currently looks at."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Watch our presentation video which has been shown at "},{"type":"element","tag":"a","props":{"href":"https://angewandtefestival.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Angewandte Festival 2021"}]},{"type":"text","value":":"}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"iframe","props":{"src":"https://player.vimeo.com/video/570870192","className":["video"],"frameBorder":"0","allow":"autoplay; fullscreen; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://spacearchitect.org/barbara-imhof/","rel":["nofollow"]},"children":[{"type":"text","value":"Barbara Imhof"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Daniela Mitterberger"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Tiziano Derme"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Patricia Tibu"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:co-corporeality-2.md","_source":"content","_file":"works/co-corporeality-2.md","_extension":"md"},{"_path":"/works/magicqueen","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Magic Queen","description":"Installation","type":"art project","year":2021,"tags":["art","music","robotics","computer vision"],"img":"/works/media/magicqueen.jpg","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Magic Queen is a hybrid environment incorporating and fusing biological systems with organic materials and machines, creating an ecosystem of empathy and coexistence. It explores the relationship among natural elements, technology, and living systems favoring the creation of an ecology of non-human subjects. It is a built habitat that can restore and nurture itself, redefining the role of living systems in architecture.It is a performative 3D-printed soil robotic garden. Sensors respond and machine learning creates continuous feedback among sensing, virtualizing, and induced change. Its inhabitable space combines visual, auditory, olfactory, and haptic features to capture the sensual experience of this new, mediated form of nature. Nothing in it could exist without the presence of the other: interconnectivity in biological entities. Fungal flora and soil structure depend on the robot to nurture them; the robot relies on their existence to move. The interconnectivity and performativity of all elements generates ambient sound and a visual interface uncovers the otherwise invisible stream of impact and growth."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"iframe","props":{"src":"https://www.youtube.com/embed/xQReQhF4Gvc","className":["video"],"title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It was exhibited at the "},{"type":"element","tag":"a","props":{"href":"https://www.labiennale.org/en/architecture/2021/among-diverse-beings/maeid-b%C3%BCro-f%C3%BCr-architektur-und-transmediale-kunst","rel":["nofollow"]},"children":[{"type":"text","value":"Biennale Architettura 2021"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"MAEID"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://medienmanufaktur.com/musikerinnen/lukaslauermann-2/","rel":["nofollow"]},"children":[{"type":"text","value":"Lukas Lauermann"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://andreareni.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Andrea Reni"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.lorem.parts","rel":["nofollow"]},"children":[{"type":"text","value":"Francesco D'Abbraccio"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.lucapagan.info/","rel":["nofollow"]},"children":[{"type":"text","value":"Luca Pagan"}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:magicqueen.md","_source":"content","_file":"works/magicqueen.md","_extension":"md"},{"_path":"/works/soundtrek","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Soundtrek","description":"Sound walk","type":"art project","img":"/works/media/blackunicorn.jpg","year":2021,"tags":["art","music","soundscape","interactive","mobile app"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The interactive installation Soundtrek provides an alternative acoustic reality for the urban walks of Klangmanifeste 2021. Just go to the Soundtrek page of the Klangmanifeste website on your smartphone, plug your earbuds in, and there we go: A generative sound composition that adapts to your surroundings. Big roads sound different than quiet side streets. Parks have a different sonic atmosphere than crowded market places. Soundtrek translates the changing moods of different urban places into music. The web based sound installation uses your geoposition to dynamically adapt to your environment. An invitation to experience a walk trought the neighbourhood in a completely new way. Augmented reality for your ears. And who knows, perhaps you will even discover some hidden acoustic easter eggs ;-)."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"iframe","props":{"src":"https://player.vimeo.com/video/537454593","className":["video"],"frameBorder":"0","allow":"autoplay; fullscreen; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Patricia Enigl, Michael Speer ("},{"type":"element","tag":"a","props":{"href":"https://soundcloud.com/b1ackunicorn","rel":["nofollow"]},"children":[{"type":"text","value":"Black Unicorn"}]},{"type":"text","value":")"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:soundtrek.md","_source":"content","_file":"works/soundtrek.md","_extension":"md"},{"_path":"/works/sylva","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Sylva","description":"A computer-controlled gardener","type":"art project","img":"/works/media/sylva.jpg","year":2021,"tags":["software development","computer vision","machine learning","python","robotics","art","raspberrypi"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"For the "},{"type":"element","tag":"a","props":{"href":"https://www.fpa.es/en/princess-of-asturias-awards/","rel":["nofollow"]},"children":[{"type":"text","value":"2021 Princess of Asturias Awards"}]},{"type":"text","value":", I collaborated with the Viennese Design Studio "},{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"MAEID"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"https://andreareni.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Andrea Reni"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"http://www.lorem.parts/","rel":["nofollow"]},"children":[{"type":"text","value":"Lorem"}]},{"type":"text","value":", "},{"type":"element","tag":"a","props":{"href":"https://global.abb/group/en","rel":["nofollow"]},"children":[{"type":"text","value":"ABB"}]},{"type":"text","value":", and "},{"type":"element","tag":"a","props":{"href":"https://camfed.org/eur/","rel":["nofollow"]},"children":[{"type":"text","value":"CAMFED"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We built a robotic gardener that nurtured a landscape with grass seeds and water. The nurturing system was mounted on two industry robots and controlled by an AI-based computer vision system, and its actions were also influenced by data that was collected by "},{"type":"element","tag":"a","props":{"href":"https://camfed.org/eur/","rel":["nofollow"]},"children":[{"type":"text","value":"CAMFED"}]},{"type":"text","value":" over the last 15 years."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"See "},{"type":"element","tag":"a","props":{"href":"https://new.abb.com/products/robotics/es/events/princesa-de-asturias","rel":["nofollow"]},"children":[{"type":"text","value":"this article"}]},{"type":"text","value":" and the video below for more information."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/crmoHesbwL0","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:sylva.md","_source":"content","_file":"works/sylva.md","_extension":"md"},{"_path":"/works/cross-perception","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Cross perception","description":"Immersive audio-visual experiment for Ars Electronica 2020","type":"art project","tags":["machine learning","computer vision","sound","fulldome","Ambisonics","Ableton Live","Max/MSP"],"year":2020,"img":"/works/media/cross-perception.png","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The human perceptual apparatus looks for simple explanations for sensory impressions. Which explanation is used for given sensory impressions depends not only on the experiences but also on the expectations of the person. In an immersive video work we create an interplay between the machine and human perception. \"Cross Perception\" aims to raise the question of how experiences and expectations shape our perception and which perspectives dominate, blur or disappear in this interplay."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The visual Part is formed by photogrammetry using a smartphone. 3D objects, their mesh structure and textures are faulty and are the basis for the visual structure in Unity. An artificial neural network for object recognition processes the 3d objects and calculates probabilities for the presence of a given set of object classes for each point in time and each image section. If an object is detected over a certain period of time, a sound is played from the direction of the corresponding image section, which is related to the detected object. For the auditory composition, granular synthesis and spectral freezes were used to create a space. The object recognition was translated into Midi Note On/Off commands and imported into Ableton Live to trigger samplers with corresponding sounds. The positions of the sound sources were calculated directly from the camera coordinates and the viewing direction."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/qkgteg1v610","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The project is part of TRANSFORM, a collaborative project between Angewandte, Johannes Kepler University, and Donau University Krems, funded by the Austrian Federal Ministry of Education, Science and Research. With the involvement of Kathrin Hunze, Thomas Hack; Silvan David Peter, Jan Schlüter (Institute for Computational Perception, JKU Linz) and Christine Böhler, Martin Gasser (Department Cross-Disciplinary Strategies, Angewandte Vienna)."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The work was shown at "},{"type":"element","tag":"a","props":{"href":"https://ars.electronica.art/keplersgardens/en/cross-perception-work/","rel":["nofollow"]},"children":[{"type":"text","value":"Ars Electronica 2020"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://raumperspektive.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Kathrin Hunze"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://raumperspektive.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Thomas Hack"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/silvan-david-peter/","rel":["nofollow"]},"children":[{"type":"text","value":"Silvan David Peter"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/jan-schlueter/","rel":["nofollow"]},"children":[{"type":"text","value":"Jan Schlüter"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.dieangewandte.at/jart/prj3/angewandte-2016/main.jart?rel=de&content-id=1458930944469&Pe-Id=7479","rel":["nofollow"]},"children":[{"type":"text","value":"Christine Böhler"}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:cross-perception.md","_source":"content","_file":"works/cross-perception.md","_extension":"md"},{"_path":"/works/amadeus","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Amadeus Active Acoustics","description":"Development of Max/MSP externals for a spatialization system","type":"development project","url":"https://www.amadeusacoustics.com/","tags":["software development","C++","Max/MSP","spatialization","sound","JavaScript","effect"],"year":2019,"img":"/works/media/amadeus.png","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"With Amadeus Acoustics, I developed highly optimized C++-based Max/MSP externals (interpolating delay matrix, eq, compressor) for a low-latency multi-channel live spatialization system running on commodity PC hardware. Furthermore, I conceptualized and implemented a web-based remote control surface for the system."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Thomas Mayr"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"http://www.fabiokaiser.eu/","rel":["nofollow"]},"children":[{"type":"text","value":"Fabio Kaiser"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Volker Werner"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:amadeus.md","_source":"content","_file":"works/amadeus.md","_extension":"md"},{"_path":"/works/co-corporeality","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Co-Corporeality","description":"Artistic Research Project","type":"research project","tags":["teaching","machine learning","computer vision","facial expression recognition"],"img":"/works/media/efeeder-coco.jpg","url":"https://cocorporeality.net/","year":2019,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Co-Corporeality addresses responsive spaces in the era of biomediality with the aim to establish an interaction between a human and a living material. We are specifically interested in developing a responsive environment within an architectural space that interacts, learns, grows and decays in relation to human presence and behaviour."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/N-ha5MOB66E","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://spacearchitect.org/barbara-imhof/","rel":["nofollow"]},"children":[{"type":"text","value":"Barbara Imhof"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Daniela Mitterberger"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maeid.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Tiziano Derme"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Damjan Minovski"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Neptun Yousefi"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Kathrin Weiland"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:co-corporeality.md","_source":"content","_file":"works/co-corporeality.md","_extension":"md"},{"_path":"/works/instant-choir","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Instant Choir","description":"Interactive theatre performance","type":"art project","year":2018,"img":"/works/media/instant-choir.jpg","tags":["theatre","performance","art","sound","mobile app","iOS","Android"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Instant Choir is a participative performance, involving audience members as protagonists who are controlled by a smartphone app. It touches critical issues such as the manipulative power of technology, its effects on interpersonal communication and behavior, and the addictive potential of Social Media and recommender systems."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I developed smartphone apps (Android & iOS) and built a Max/MSP-based system for controlling stage visuals, audio, and smartphone apps from an on-stage iPad."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"width":"100%","height":600,"src":"https://www.youtube.com/embed/D0lvkT1ewrc","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Mimu Merz"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"http://www.cquence.at/","rel":["nofollow"]},"children":[{"type":"text","value":"C'quence"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://medienmanufaktur.com/musikerinnen/lukaslauermann-2/","rel":["nofollow"]},"children":[{"type":"text","value":"Lukas Lauermann"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Markus Zahradnik"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:instant-choir.md","_source":"content","_file":"works/instant-choir.md","_extension":"md"},{"_path":"/works/midiq","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"MidiQ","description":"Midi plug-in","type":"development project","tags":["software development","audio plugin","MIDI","music","effect","sound","C++","JUCE"],"img":"/works/media/midiq.png","year":2018,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"MIDI plug-in for chord sequence generation from statistical models."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n  "},{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/vPLxm5Pg_7E","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.waproduction.com/plugins/view/midiq","rel":["nofollow"]},"children":[{"type":"text","value":"W.A. Production MIDIQ"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"http://www.ehu.eus/cs-ikerbasque/conklin/","rel":["nofollow"]},"children":[{"type":"text","value":"Darrell Conklin"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Stefan Oertl"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Roland Trimmel"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Zofia Zin"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:midiq.md","_source":"content","_file":"works/midiq.md","_extension":"md"},{"_path":"/works/venom","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Venom","description":"Audio plug-in","type":"development project","url":"https://www.waproduction.com/plugins/view/venom","tags":["software development","audio plugin","music","effect","C++","JUCE"],"img":"/works/media/venom.png","year":2018,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Conceptualization and implementation of a plug-in for spectral processing of audio data."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/euPZ60HPOMA","title":"YouTube video player","frameBorder":"0","allow":"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.canto-crudo.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Guenther Rabl"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Stefan Oertl"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Roland Trimmel"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Zofia Zin"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:venom.md","_source":"content","_file":"works/venom.md","_extension":"md"},{"_path":"/works/meat-transformer","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Meat Transformer","description":"Live Music Act","type":"art project","tags":["music","composition","stage design","performance","Ableton Live","Logic Pro","Guitar"],"img":"/works/media/meat-transformer.png","year":2016,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Music-theatre-performance project, various incarnations from duo with laptop,\nvocals, and guitar to a full-blown live band."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/AlYNAktkxsY","frameBorder":"0","allow":"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.dieangewandte.at/jart/prj3/angewandte-2016/main.jart?rel=de&reserve-mode=active&content-id=1458930944469&Pe-Id=5380","rel":["nofollow"]},"children":[{"type":"text","value":"Robert Maierhofer"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Sascha Müller"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Daniel Müller"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.triktronics.at/","rel":["nofollow"]},"children":[{"type":"text","value":"Klaus Trippl"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.mdw.ac.at/imp/?PageId=3819","rel":["nofollow"]},"children":[{"type":"text","value":"Uli Permanschlager"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Christoph Hausner"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:meat-transformer.md","_source":"content","_file":"works/meat-transformer.md","_extension":"md"},{"_path":"/works/phenicx","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"PhenicX","description":"EU-funded research project","type":"research project","year":2016,"roles":["Development of score-performance matching technology","Development of web-based music visualization technology","Development of realtime score following technology"],"tags":["research","machine learning","music","software development","Python","C++","JavaScript"],"img":"/works/media/phenicx.jpg","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"PHENICX is a collaborative research project, partially funded by the European commission. In this project, academic researchers, music institutions, musicians and up-and-coming technology companies join forces. Our mission is to make use of all the richness around classical music: the sound you can hear, the players you can see. The characteristics of a piece, and the differences between multiple performances of the same piece. The background stories behind a piece, and the way it is perceived by different types of audiences. Through smart use of technology, we want to use this richness to build a whole new classical concert experience. A concert experience that can guide you through a performance, with information tailored to varying expertise levels. A concert experience that allows you to get an impression of a piece before a concert, enriches the experience during a concert, and lets you revisit the concert after it was played, allowing you to discover new things about it. A concert experience that even may initiate a social discussion based on your impressions and the impressions of other attendees. All of this is not meant to defy the traditional concert experience, but to offer you new engaging experiences on top of it."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"See also the PhenicX "},{"type":"element","tag":"a","props":{"href":"http://phenicx.upf.edu/","rel":["nofollow"]},"children":[{"type":"text","value":"web site"}]},{"type":"text","value":"."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:phenicx.md","_source":"content","_file":"works/phenicx.md","_extension":"md"},{"_path":"/works/ai-concertgebouw","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Artificial Intelligence in the Concertgebouw","description":"Artificial Intelligence in the Concertgebouw","type":"research paper","tags":["research"],"img":"/works/media/concertgebouw.jpg","year":2015,"pdfUrls":["https://www.ijcai.org/Proceedings/15/Papers/343.pdf"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this paper we present a real-world application (the first of its kind) of\nmachine listening in the context of a live concert in a world-famous concert\nhall – the Concertgebouw in Amsterdam. A real-time music tracking algorithm\nlistens to the Royal Concertgebouw Orchestra performing Richard Strauss’\nAlpensinfonie and follows the progress in the sheet music, i.e., continuously\ntracks the most likely position of the live music in the printed score.\nThis information, in turn, is used to enrich the concert experience for\nmembers of the audience by streaming synchronised visual content\n(the sheet music, explanatory text and videos) onto tablet computers\nin the concert hall. The main focus of this paper is on the challenges\ninvolved in tracking live orchestral music, i.e., how to deal with heavily\npolyphonic music, how to prepare the data needed, and how to achieve the\nnecessary robustness and precision."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.andreas-arzt.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Andreas Arzt"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/harald-frostel/","rel":["nofollow"]},"children":[{"type":"text","value":"Harald Frostel"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/institut-fuer-computational-perception/ueber-uns/mitarbeiterinnen/thassilo-gadermaier/","rel":["nofollow"]},"children":[{"type":"text","value":"Thassilo Gadermaier"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maarten.grachten.eu/","rel":["nofollow"]},"children":[{"type":"text","value":"Maarten Grachten"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/gerhard-widmer/","rel":["nofollow"]},"children":[{"type":"text","value":"Gerhard Widmer"}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:ai-concertgebouw.md","_source":"content","_file":"works/ai-concertgebouw.md","_extension":"md"},{"_path":"/works/body-tweets","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Body/Tweets","description":"Interactive sonification experiment","type":"art project","img":"/works/media/body-tweets.png","year":2014,"tags":["art","sound","installation","visuals","Twitter","Supercollider","Cinder","C++"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Live sonification of a Twitter live feed; keywords trigger granular synthesis from body noise."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://player.vimeo.com/video/172708892","frameBorder":"0","allow":"autoplay; fullscreen","allowFullScreen":true},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://vimeo.com/172708892"},"children":[{"type":"text","value":"Body:Tweets"}]},{"type":"text","value":" from "},{"type":"element","tag":"a","props":{"href":"https://vimeo.com/user13355697"},"children":[{"type":"text","value":"Martin Gasser"}]},{"type":"text","value":" on "},{"type":"element","tag":"a","props":{"href":"https://vimeo.com"},"children":[{"type":"text","value":"Vimeo"}]},{"type":"text","value":"."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:body-tweets.md","_source":"content","_file":"works/body-tweets.md","_extension":"md"},{"_path":"/works/classical-music-web","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Classical Music on the Web – User Interfaces and Data Representations","description":"Research paper that describes various possibilities to handle and visualize complex classical music data in  web-based environments.","type":"research paper","img":"/works/media/cmotw.png","tags":["research"],"year":2014,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We present a set of web-based user interfaces for explorative analysis and visualization of classical orchestral music and a web API that serves as a backend to those applications; we describe use cases that motivated our developments within the PHENICX project, which promotes a vital interaction between Music Information Retrieval research groups and a world-renowned symphony orchestra. Furthermore, we describe two real-world applications that involve the work presented here. Firstly, our web applications are used in the editorial stage of a periodically released subscription-based mobile app by the Royal Concertgebouw Orchestra (RCO) 1 , which serves as a contentdistribution channel for multi-modally enhanced recordings of classical concerts. Secondly, our web API and user interfaces have been successfully used to provide real-time information (such as the score, and explanatory comments from musicologists) to the audience during a live concert of the RCO."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.andreas-arzt.com/","rel":["nofollow"]},"children":[{"type":"text","value":"Andreas Arzt"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/harald-frostel/","rel":["nofollow"]},"children":[{"type":"text","value":"Harald Frostel"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/institut-fuer-computational-perception/ueber-uns/mitarbeiterinnen/thassilo-gadermaier/","rel":["nofollow"]},"children":[{"type":"text","value":"Thassilo Gadermaier"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://maarten.grachten.eu/","rel":["nofollow"]},"children":[{"type":"text","value":"Maarten Grachten"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.jku.at/en/institute-of-computational-perception/about-us/people/gerhard-widmer/","rel":["nofollow"]},"children":[{"type":"text","value":"Gerhard Widmer"}]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:classical-music-web.md","_source":"content","_file":"works/classical-music-web.md","_extension":"md"},{"_path":"/works/brainwash","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Brainwash / Gehirnwäsche","description":"Modified washing machine","type":"art project","year":2011,"tags":["art","hacking","video","installation","mobile app"],"img":"/works/media/brainwash-1.jpg","body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Closed-circuit video installation, built from a deranged washing machine with a\nlittle help from a video camera, a Raspberry Pi, and a screen."}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n  "},{"type":"element","tag":"iframe","props":{"src":"https://player.vimeo.com/video/204761873","className":["video"],"frameBorder":"0","allow":"autoplay; fullscreen","allowFullScreen":true},"children":[{"type":"text","value":"\n  "}]}]},{"type":"element","tag":"div","props":{"className":["video-container"]},"children":[{"type":"text","value":"\n  "},{"type":"element","tag":"iframe","props":{"className":["video"],"src":"https://www.youtube.com/embed/1KG0YLNkUZc","frameBorder":"0","allow":"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture","allowFullScreen":true},"children":[{"type":"text","value":"\n  "}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"collaborators:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.anneglassner.at","rel":["nofollow"]},"children":[{"type":"text","value":"Anne Glassner"}]}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Stefan Pomajbik"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Dirk Budig"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:brainwash.md","_source":"content","_file":"works/brainwash.md","_extension":"md"},{"_path":"/works/flower","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Flower","description":"A flow-based high-performance C++ data processing framework","type":"development project","tags":["software development","research","C++","dataflow","cross platform","embedded"],"img":"/works/media/flower.png","year":2010,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Dataflow-oriented C++ software framework for component-oriented development of realtime sound- and music-processing software. Heavily used in-house and as part of the "},{"type":"element","tag":"a","props":{"href":"phenicx"},"children":[{"type":"text","value":"PhenicX"}]},{"type":"text","value":" project."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:flower.md","_source":"content","_file":"works/flower.md","_extension":"md"},{"_path":"/works/fm4-soundpark","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"FM4 soundpark music recommender","description":"Integration of a content-based music recommendation system in the FM4 Soundpark","type":"R&D project","tags":["software development","machine learning","music similarity","Python","C++"],"img":"/works/media/soundpark.png","year":2009,"pdfUrls":["http://www.ofai.at/cgi-bin/get-tr?download=1&paper=oefai-tr-2009-02.pdf"],"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We present an application of content-based music recommendation techniques within an online community platform\ntargeted at an audience interested mainly in independent and\nalternative music. The web platform’s goals will be described, the problems of content management approaches\nbased on daily publishing of new music tracks will be discussed, and we will give an overview of the user interfaces\nthat have been developed to simplify access to the music\ncollection. Finally, the adoption of content-based music recommendation tools and new user interfaces to improve user\nacceptance and recommendation quality will be justified by\ndetailed user access analyses."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:fm4-soundpark.md","_source":"content","_file":"works/fm4-soundpark.md","_extension":"md"},{"_path":"/works/heartbeat","_dir":"works","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Heartbeat","description":"Installation for Ars Electronica 2005","type":"art project","collaborators":["Institute for Pervasive Computing, University Linz","Institute for Computational Perception, University Linz"],"tags":["art","music","sound","biosignals","Supercollider"],"img":"/works/media/heartbeat.png","year":2005,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"People in love with each other claim to exhibit the \"same heartbeat\". The installation \"HeartBeat\" aims at detecting biological similarities among the ECG signals generated by two individuals, and by involving a complex mathematical model for similarity analysis. The degree of correspondence is used to express heartbeat harmony as a musical intonation, and to steer a large-format visualization. Out of pre-recorded heartbeats, visitors can find people \"matching\" their own heartbeat."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Exhibited at Ars Electronic 2005."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:works:heartbeat.md","_source":"content","_file":"works/heartbeat.md","_extension":"md"}]